{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary stuff and python-wrapper of verse\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import codecs\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from verse.python.wrapper import VERSE\n",
    "from multi_class_classification import MultiClassClassification\n",
    "from multi_label_classification import MultiLabelClassification\n",
    "from clustering import Clustering\n",
    "from link_prediction import LinkPrediction\n",
    "from experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize pretty printer\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure telegram notifier bot\n",
    "my_telegram_config = {\n",
    "    \"telegram\": {\n",
    "        \"token\": \"350553078:AAEu70JDqMFcG_x5eBD3nqccTvc4aFNMKkg\",\n",
    "        \"chat_id\": \"126551968\",\n",
    "        \"verbose\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path = 'data/coauthor/'\n",
    "coauthor_crawled_data_file_path = dataset_path + 'coauthor_crawled_data.p'\n",
    "EXPORT_AS_EDGE_LIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(coauthor_crawled_data_file_path, 'rb') as pickle_file:\n",
    "    coauthor_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define research fields and years of interest for us\n",
    "fields_of_studies = ['Machine learning']\n",
    "years = [2013,2014,2015,2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract top 5 conferences per field of research\n",
    "top_5_conf_series_per_field = {}\n",
    "for field_of_study in fields_of_studies:\n",
    "    top_5_conf_series_per_field[field_of_study] = coauthor_data[field_of_study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define networkx graph\n",
    "coauthor_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define node and edge label constants\n",
    "AUTHOR = 'author'\n",
    "PAPER = 'paper'\n",
    "CO_AUTHOR = 'co_author_of'\n",
    "REFERENCES = 'references'\n",
    "WRITTEN_BY = 'written_by'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30896 author and paper nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add authors and papers\n",
    "for field_of_study in coauthor_data.keys():\n",
    "    for conference in coauthor_data[field_of_study].keys():\n",
    "        for year in coauthor_data[field_of_study][conference].keys():\n",
    "            for i, paper in enumerate(coauthor_data[field_of_study][conference][year]):\n",
    "                coauthor_graph.add_node('P' + str(paper['Id']), num_citations=paper['CC'], num_references=len(paper['RId']),\n",
    "                                        conference=conference, field_of_study=field_of_study, label=PAPER)\n",
    "                for author in coauthor_data[field_of_study][conference][year][i]['authors']:\n",
    "                    coauthor_graph.add_node('A' + str(author), label=AUTHOR)\n",
    "\n",
    "print(\"{} author and paper nodes in graph\".format(coauthor_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30896 nodes in graph\n",
      "99578 edges in graph\n"
     ]
    }
   ],
   "source": [
    "# add co-author, written_by and reference edge\n",
    "for field_of_study in coauthor_data.keys():\n",
    "    for conference in coauthor_data[field_of_study].keys():\n",
    "        for year in coauthor_data[field_of_study][conference].keys():\n",
    "            for i, paper in enumerate(coauthor_data[field_of_study][conference][year]):\n",
    "                for referenced_paper_id in paper['RId']:\n",
    "                    if 'P' + str(referenced_paper_id) in coauthor_graph:\n",
    "                        coauthor_graph.add_edge('P' + str(paper['Id']), 'P' + str(referenced_paper_id),\n",
    "                                                label=REFERENCES)\n",
    "                for author in coauthor_data[field_of_study][conference][year][i]['authors']:\n",
    "                    coauthor_graph.add_edge('P' + str(paper['Id']), 'A' + str(author), label=WRITTEN_BY)\n",
    "                    for co_author in coauthor_data[field_of_study][conference][year][i]['authors']:\n",
    "                        if author != co_author:\n",
    "                            coauthor_graph.add_edge('A' + str(author), 'A' + str(co_author), label=CO_AUTHOR)\n",
    "\n",
    "print(\"{} nodes in graph\".format(coauthor_graph.number_of_nodes()))\n",
    "print(\"{} edges in graph\".format(coauthor_graph.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg. node degree is 6.45\n"
     ]
    }
   ],
   "source": [
    "# compute average degree of all nodes in graph\n",
    "node_degrees = np.array(list(dict(coauthor_graph.degree(list(coauthor_graph.nodes))).values()),dtype=np.int64)\n",
    "avg_node_degree = np.mean(node_degrees)\n",
    "print(\"The avg. node degree is {}\".format(np.round(avg_node_degree, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect conference label mapping\n",
    "conf_count = 0\n",
    "conference_label_mapping = {}\n",
    "for field_of_study in coauthor_data.keys():\n",
    "    for conference in coauthor_data[field_of_study].keys():\n",
    "        conference_label_mapping[conference] = conf_count\n",
    "        conf_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper nodes \n",
    "paper_nodes = [node for node, attr in coauthor_graph.nodes(data=True) if attr['label'] == PAPER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect conference class label for each paper\n",
    "paper_conference_labels = {}\n",
    "for paper in paper_nodes:\n",
    "    paper_conference = coauthor_graph.nodes[paper]['conference']\n",
    "    paper_conference_labels[paper] = conference_label_mapping[paper_conference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.emb file with precomputed verse-ppr embeddings\n",
    "n_hidden = 128\n",
    "results_path = 'results/coauthor/'\n",
    "embeddings_file_path = results_path + 'coauthor_verse_ppr_embeddings.emb'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "verse_ppr_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.emb file with precomputed node2vec embeddings\n",
    "embeddings_file_path = results_path + 'coauthor_node2vec_embeddings.emb'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "node2vec_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.emb file with precomputed node2vec embeddings\n",
    "embeddings_file_path = results_path + 'coauthor_deepwalk_embeddings.emb'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "deepwalk_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load id-to-node mapping of verse embeddings\n",
    "id2node_filepath = dataset_path + 'coauthor_mapping_ids_to_nodes.p'\n",
    "with open(id2node_filepath, 'rb') as id_2_node_file:\n",
    "    id2node = pickle.load(id_2_node_file)\n",
    "\n",
    "# load node-to-id mapping of verse embeddings\n",
    "node2id_filepath = dataset_path + 'coauthor_mapping_nodes_to_ids.p'\n",
    "with open(node2id_filepath, 'rb') as node_2_id_file:\n",
    "    node2id = pickle.load(node_2_id_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper train data from verse embeddings\n",
    "paper_verse_embeddings = []\n",
    "paper_labels = []\n",
    "for paper in paper_nodes:\n",
    "    paper_index = node2id[paper]\n",
    "    paper_verse_embeddings.append(verse_ppr_embeddings[paper_index])\n",
    "    paper_labels.append(paper_conference_labels[paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiment types\n",
    "CLUSTERING = 'clustering'\n",
    "CLASSIFICATION = 'classification'\n",
    "MULTI_LABEL_CLASSIFICATION = 'multi_label_classification'\n",
    "LINK_PREDICTION = 'link_prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init classification experiment on verse-ppr embedding\n",
    "random_seed = 42\n",
    "num_of_reps = 2\n",
    "random_seeds = list(range(42,42+num_of_reps))\n",
    "train_sizes = [i/20 for i in range(1,3,1)]\n",
    "results_json_path = results_path + 'coauthor_verse_ppr_conference_classification.json'\n",
    "results_pickle_path = results_path + 'coauthor_verse_ppr_conference_classification_exp.p'\n",
    "coauthor_verse_ppr_classification_experiment = Experiment(method_name='Verse-PPR', dataset_name='co-author', performance_function='both',\n",
    "                                  node_labels=paper_labels, repetitions=num_of_reps, node_embedings=paper_verse_embeddings,\n",
    "                                  embedding_dimensionality=n_hidden, experiment_params={'train_size': train_sizes},\n",
    "                                  results_file_path=results_json_path, experiment_type=CLASSIFICATION,\n",
    "                                  random_seeds=random_seeds, pickle_path=results_pickle_path,\n",
    "                                  telegram_config=my_telegram_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start classification experiment on co-author data set with Verse-PPR embeddings\n",
      "Repeated 2 times and evaluated through bothperformance function(s)\n",
      "Initialize multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "Train multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "Train multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "convergence after 93 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.71 sec.!\n",
      "Predict multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "Predicted multi-class classification experiment in 0.03 sec.!\n",
      "Evaluate multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "convergence after 96 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.73 sec.!\n",
      "Predict multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with Verse-PPR on co-author evaluated through both on 5.0% train data!\n",
      "Initialize multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "Train multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "Train multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "convergence after 66 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.81 sec.!\n",
      "Predict multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "convergence after 62 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.93 sec.!\n",
      "Predict multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "Predicted multi-class classification experiment in 0.03 sec.!\n",
      "Evaluate multi-class classification experiment with Verse-PPR on co-author evaluated through both on 10.0% train data!\n",
      "Finished classification experiment on co-author data set with Verse-PPR embeddings\n",
      "Saved results in file results/coauthor/coauthor_verse_ppr_conference_classification.json\n",
      "Saved experiment as pickle-model in file results/coauthor/coauthor_verse_ppr_conference_classification_exp.p\n"
     ]
    }
   ],
   "source": [
    "# run experiment wrapper: train, predict and evaluate conference classification on verse-ppr embeddings\n",
    "coauthor_verse_ppr_classification_experiment_results = coauthor_verse_ppr_classification_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper train data from node2vec embeddings\n",
    "paper_node2vec_embeddings = []\n",
    "paper_labels = []\n",
    "for paper in paper_nodes:\n",
    "    paper_index = node2id[paper]\n",
    "    paper_node2vec_embeddings.append(node2vec_embeddings[paper_index])\n",
    "    paper_labels.append(paper_conference_labels[paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init classification experiment on node2vec embedding\n",
    "random_seed = 42\n",
    "num_of_reps = 2\n",
    "random_seeds = list(range(42,42+num_of_reps))\n",
    "train_sizes = [i/20 for i in range(1,3,1)]\n",
    "results_json_path = results_path + 'coauthor_node2vec_conference_classification.json'\n",
    "results_pickle_path = results_path + 'coauthor_node2vec_conference_classification_exp.p'\n",
    "coauthor_node2vec_classification_experiment = Experiment(method_name='node2vec', dataset_name='co-author', performance_function='both',\n",
    "                                  node_labels=paper_labels, repetitions=num_of_reps, node_embedings=paper_node2vec_embeddings,\n",
    "                                  embedding_dimensionality=n_hidden, experiment_params={'train_size': train_sizes},\n",
    "                                  results_file_path=results_json_path, experiment_type=CLASSIFICATION,\n",
    "                                  random_seeds=random_seeds, pickle_path=results_pickle_path,\n",
    "                                  telegram_config=my_telegram_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start classification experiment on co-author data set with node2vec embeddings\n",
      "Repeated 2 times and evaluated through bothperformance function(s)\n",
      "Initialize multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "Train multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "Train multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "max_iter reached after 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.81 sec.!\n",
      "Predict multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "max_iter reached after 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.74 sec.!\n",
      "Predict multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with node2vec on co-author evaluated through both on 5.0% train data!\n",
      "Initialize multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "Train multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "Train multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 1.41 sec.!\n",
      "Predict multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "max_iter reached after 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 1.41 sec.!\n",
      "Predict multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with node2vec on co-author evaluated through both on 10.0% train data!\n",
      "Finished classification experiment on co-author data set with node2vec embeddings\n",
      "Saved results in file results/coauthor/coauthor_node2vec_conference_classification.json\n",
      "Saved experiment as pickle-model in file results/coauthor/coauthor_node2vec_conference_classification_exp.p\n"
     ]
    }
   ],
   "source": [
    "# run experiment wrapper: train, predict and evaluate conference classification on node2vec embeddings\n",
    "coauthor_node2vec_classification_experiment_results = coauthor_node2vec_classification_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper train data from deepwalk embeddings\n",
    "paper_deepwalk_embeddings = []\n",
    "paper_labels = []\n",
    "for paper in paper_nodes:\n",
    "    paper_index = node2id[paper]\n",
    "    paper_deepwalk_embeddings.append(deepwalk_embeddings[paper_index])\n",
    "    paper_labels.append(paper_conference_labels[paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init classification experiment on deepwalk embedding\n",
    "random_seed = 42\n",
    "num_of_reps = 2\n",
    "random_seeds = list(range(42,42+num_of_reps))\n",
    "train_sizes = [i/20 for i in range(1,3,1)]\n",
    "results_json_path = results_path + 'coauthor_deepwalk_conference_classification.json'\n",
    "results_pickle_path = results_path + 'coauthor_deepwalk_conference_classification_exp.p'\n",
    "coauthor_deepwalk_classification_experiment = Experiment(method_name='deepwalk', dataset_name='co-author', performance_function='both',\n",
    "                                  node_labels=paper_labels, repetitions=num_of_reps, node_embedings=paper_deepwalk_embeddings,\n",
    "                                  embedding_dimensionality=n_hidden, experiment_params={'train_size': train_sizes},\n",
    "                                  results_file_path=results_json_path, experiment_type=CLASSIFICATION,\n",
    "                                  random_seeds=random_seeds, pickle_path=results_pickle_path,\n",
    "                                  telegram_config=my_telegram_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start classification experiment on co-author data set with deepwalk embeddings\n",
      "Repeated 2 times and evaluated through bothperformance function(s)\n",
      "Initialize multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "Train multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "Train multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "max_iter reached after 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.6 sec.!\n",
      "Predict multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "max_iter reached after 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 0.71 sec.!\n",
      "Predict multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with deepwalk on co-author evaluated through both on 5.0% train data!\n",
      "Initialize multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "Train multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "Train multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 1.41 sec.!\n",
      "Predict multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "Predicted multi-class classification experiment in 0.02 sec.!\n",
      "Evaluate multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "max_iter reached after 2 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained multi-class classification experiment in 1.41 sec.!\n",
      "Predict multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "Predicted multi-class classification experiment in 0.01 sec.!\n",
      "Evaluate multi-class classification experiment with deepwalk on co-author evaluated through both on 10.0% train data!\n",
      "Finished classification experiment on co-author data set with deepwalk embeddings\n",
      "Saved results in file results/coauthor/coauthor_deepwalk_conference_classification.json\n",
      "Saved experiment as pickle-model in file results/coauthor/coauthor_deepwalk_conference_classification_exp.p\n"
     ]
    }
   ],
   "source": [
    "# run experiment wrapper: train, predict and evaluate conference classification on deepwalk embeddings\n",
    "coauthor_deepwalk_classification_experiment_results = coauthor_deepwalk_classification_experiment.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
