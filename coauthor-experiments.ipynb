{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary stuff and python-wrapper of verse\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "import codecs\n",
    "import networkx as nx\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from verse.python.wrapper import VERSE\n",
    "from multi_class_classification import MultiClassClassification\n",
    "from multi_label_classification import MultiLabelClassification\n",
    "from clustering import Clustering\n",
    "from link_prediction import LinkPrediction\n",
    "from experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize pretty printer\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure telegram notifier bot\n",
    "my_telegram_config = {\n",
    "    \"telegram\": {\n",
    "        \"token\": \"350553078:AAEu70JDqMFcG_x5eBD3nqccTvc4aFNMKkg\",\n",
    "        \"chat_id\": \"126551968\",\n",
    "        \"verbose\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_path = 'data/coauthor/'\n",
    "coauthor_crawled_data_file_path = dataset_path + 'coauthor_crawled_data.p'\n",
    "EXPORT_AS_EDGE_LIST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(coauthor_crawled_data_file_path, 'rb') as pickle_file:\n",
    "    coauthor_data = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define research fields and years of interest for us\n",
    "fields_of_studies = ['Machine learning']\n",
    "years = [2013,2014,2015,2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract top 5 conferences per field of research\n",
    "top_5_conf_series_per_field = {}\n",
    "for field_of_study in fields_of_studies:\n",
    "    top_5_conf_series_per_field[field_of_study] = coauthor_data[field_of_study]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define networkx graph\n",
    "with open(dataset_path + 'coauthor_networkx.p', 'rb') as pickle_file:\n",
    "    coauthor_graph = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define node and edge label constants\n",
    "AUTHOR = 'author'\n",
    "PAPER = 'paper'\n",
    "CO_AUTHOR = 'co_author_of'\n",
    "REFERENCES = 'references'\n",
    "WRITTEN_BY = 'written_by'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg. node degree is 6.45\n",
      "30896 nodes in graph\n",
      "99578 edges in graph\n"
     ]
    }
   ],
   "source": [
    "# compute average degree of all nodes in graph\n",
    "node_degrees = np.array(list(dict(coauthor_graph.degree(list(coauthor_graph.nodes))).values()),dtype=np.int64)\n",
    "avg_node_degree = np.mean(node_degrees)\n",
    "print(\"The avg. node degree is {}\".format(np.round(avg_node_degree, decimals=2)))\n",
    "\n",
    "print(\"{} nodes in graph\".format(coauthor_graph.number_of_nodes()))\n",
    "print(\"{} edges in graph\".format(coauthor_graph.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect conference label mapping\n",
    "conf_count = 0\n",
    "conference_label_mapping = {}\n",
    "for field_of_study in coauthor_data.keys():\n",
    "    for conference in coauthor_data[field_of_study].keys():\n",
    "        conference_label_mapping[conference] = conf_count\n",
    "        conf_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper nodes \n",
    "paper_nodes = [node for node, attr in coauthor_graph.nodes(data=True) if attr['label'] == PAPER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect conference class label for each paper\n",
    "paper_conference_labels = {}\n",
    "for paper in paper_nodes:\n",
    "    paper_conference = coauthor_graph.nodes[paper]['conference']\n",
    "    paper_conference_labels[paper] = conference_label_mapping[paper_conference]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.emb file with precomputed verse-ppr embeddings\n",
    "n_hidden = 128\n",
    "results_path = 'results/coauthor/'\n",
    "embeddings_file_path = results_path + 'coauthor_verse_ppr_embeddings.emb'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "verse_ppr_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.emb file with precomputed node2vec embeddings\n",
    "embeddings_file_path = results_path + 'coauthor_node2vec_embeddings.emb'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "node2vec_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.emb file with precomputed node2vec embeddings\n",
    "embeddings_file_path = results_path + 'coauthor_deepwalk_embeddings.emb'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "deepwalk_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load id-to-node mapping of verse embeddings\n",
    "id2node_filepath = dataset_path + 'coauthor_mapping_ids_to_nodes.p'\n",
    "with open(id2node_filepath, 'rb') as id_2_node_file:\n",
    "    id2node = pickle.load(id_2_node_file)\n",
    "\n",
    "# load node-to-id mapping of verse embeddings\n",
    "node2id_filepath = dataset_path + 'coauthor_mapping_nodes_to_ids.p'\n",
    "with open(node2id_filepath, 'rb') as node_2_id_file:\n",
    "    node2id = pickle.load(node_2_id_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper train data from verse embeddings\n",
    "paper_verse_embeddings = []\n",
    "paper_labels = []\n",
    "for paper in paper_nodes:\n",
    "    paper_index = node2id[paper]\n",
    "    paper_verse_embeddings.append(verse_ppr_embeddings[paper_index])\n",
    "    paper_labels.append(paper_conference_labels[paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# experiment types\n",
    "CLUSTERING = 'clustering'\n",
    "CLASSIFICATION = 'classification'\n",
    "MULTI_LABEL_CLASSIFICATION = 'multi_label_classification'\n",
    "LINK_PREDICTION = 'link_prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init classification experiment on verse-ppr embedding\n",
    "random_seed = 42\n",
    "num_of_reps = 2\n",
    "random_seeds = list(range(42,42+num_of_reps))\n",
    "train_sizes = [i/20 for i in range(1,3,1)]\n",
    "results_json_path = results_path + 'coauthor_verse_ppr_conference_classification.json'\n",
    "results_pickle_path = results_path + 'coauthor_verse_ppr_conference_classification_exp.p'\n",
    "coauthor_verse_ppr_classification_experiment = Experiment(method_name='Verse-PPR', dataset_name='co-author', performance_function='both',\n",
    "                                  node_labels=paper_labels, repetitions=num_of_reps, node_embedings=paper_verse_embeddings,\n",
    "                                  embedding_dimensionality=n_hidden, experiment_params={'train_size': train_sizes},\n",
    "                                  results_file_path=results_json_path, experiment_type=CLASSIFICATION,\n",
    "                                  random_seeds=random_seeds, pickle_path=results_pickle_path,\n",
    "                                  telegram_config=my_telegram_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run experiment wrapper: train, predict and evaluate conference classification on verse-ppr embeddings\n",
    "coauthor_verse_ppr_classification_experiment_results = coauthor_verse_ppr_classification_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper train data from node2vec embeddings\n",
    "paper_node2vec_embeddings = []\n",
    "paper_labels = []\n",
    "for paper in paper_nodes:\n",
    "    paper_index = node2id[paper]\n",
    "    paper_node2vec_embeddings.append(node2vec_embeddings[paper_index])\n",
    "    paper_labels.append(paper_conference_labels[paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init classification experiment on node2vec embedding\n",
    "random_seed = 42\n",
    "num_of_reps = 2\n",
    "random_seeds = list(range(42,42+num_of_reps))\n",
    "train_sizes = [i/20 for i in range(1,3,1)]\n",
    "results_json_path = results_path + 'coauthor_node2vec_conference_classification.json'\n",
    "results_pickle_path = results_path + 'coauthor_node2vec_conference_classification_exp.p'\n",
    "coauthor_node2vec_classification_experiment = Experiment(method_name='node2vec', dataset_name='co-author', performance_function='both',\n",
    "                                  node_labels=paper_labels, repetitions=num_of_reps, node_embedings=paper_node2vec_embeddings,\n",
    "                                  embedding_dimensionality=n_hidden, experiment_params={'train_size': train_sizes},\n",
    "                                  results_file_path=results_json_path, experiment_type=CLASSIFICATION,\n",
    "                                  random_seeds=random_seeds, pickle_path=results_pickle_path,\n",
    "                                  telegram_config=my_telegram_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run experiment wrapper: train, predict and evaluate conference classification on node2vec embeddings\n",
    "coauthor_node2vec_classification_experiment_results = coauthor_node2vec_classification_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect paper train data from deepwalk embeddings\n",
    "paper_deepwalk_embeddings = []\n",
    "paper_labels = []\n",
    "for paper in paper_nodes:\n",
    "    paper_index = node2id[paper]\n",
    "    paper_deepwalk_embeddings.append(deepwalk_embeddings[paper_index])\n",
    "    paper_labels.append(paper_conference_labels[paper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init classification experiment on deepwalk embedding\n",
    "random_seed = 42\n",
    "num_of_reps = 2\n",
    "random_seeds = list(range(42,42+num_of_reps))\n",
    "train_sizes = [i/20 for i in range(1,3,1)]\n",
    "results_json_path = results_path + 'coauthor_deepwalk_conference_classification.json'\n",
    "results_pickle_path = results_path + 'coauthor_deepwalk_conference_classification_exp.p'\n",
    "coauthor_deepwalk_classification_experiment = Experiment(method_name='deepwalk', dataset_name='co-author', performance_function='both',\n",
    "                                  node_labels=paper_labels, repetitions=num_of_reps, node_embedings=paper_deepwalk_embeddings,\n",
    "                                  embedding_dimensionality=n_hidden, experiment_params={'train_size': train_sizes},\n",
    "                                  results_file_path=results_json_path, experiment_type=CLASSIFICATION,\n",
    "                                  random_seeds=random_seeds, pickle_path=results_pickle_path,\n",
    "                                  telegram_config=my_telegram_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run experiment wrapper: train, predict and evaluate conference classification on deepwalk embeddings\n",
    "coauthor_deepwalk_classification_experiment_results = coauthor_deepwalk_classification_experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all authors, collect all conferences, an autor published in papers\n",
    "author_nodes = [node for node, attr in coauthor_graph.nodes(data=True) if attr['label'] == AUTHOR]\n",
    "author_conference_labels = {}\n",
    "for author in author_nodes:\n",
    "    author_conference_labels[author] = []\n",
    "    for neighbor in coauthor_graph[author]:\n",
    "        if coauthor_graph.nodes[neighbor]['label'] == PAPER:\n",
    "            author_conference_labels[author].append(coauthor_graph.nodes[neighbor]['conference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all authors find conference, they published in most papers\n",
    "from scipy import stats\n",
    "\n",
    "for author in author_conference_labels.keys():\n",
    "    author_conference_labels[author] = stats.mode(author_conference_labels[author]).mode[0]\n",
    "    author_conference_labels[author] = conference_label_mapping[author_conference_labels[author]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# collect author train data from verse embeddings\n",
    "author_verse_embeddings = []\n",
    "author_labels = []\n",
    "for author in author_nodes:\n",
    "    author_index = node2id[author]\n",
    "    author_verse_embeddings.append(verse_ppr_embeddings[author_index])\n",
    "    author_labels.append(author_conference_labels[author])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
