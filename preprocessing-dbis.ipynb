{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import time\n",
    "import pickle\n",
    "import pprint\n",
    "import chardet\n",
    "from telegram import Bot\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize pretty printer\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initilize telegram bot\n",
    "token = \"350553078:AAEu70JDqMFcG_x5eBD3nqccTvc4aFNMKkg\"\n",
    "chat_id = \"126551968\"\n",
    "bot = Bot(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define dataset file paths\n",
    "dataset_path = 'data/net_dbis/'\n",
    "authors_csv_path = dataset_path + 'id_author.txt'\n",
    "conferences_csv_path = dataset_path + 'id_conf.txt'\n",
    "papers_csv_path = dataset_path + 'paper.txt'\n",
    "paper_author_edges_csv_path = dataset_path + 'paper_author.txt'\n",
    "paper_conference_edges_csv_path = dataset_path + 'paper_conf.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'data/net_dbis/id_author.txt': {   'confidence': 0.720934677925103,\n",
      "                                       'encoding': 'ISO-8859-1',\n",
      "                                       'language': ''},\n",
      "    'data/net_dbis/id_conf.txt': {   'confidence': 0.73,\n",
      "                                     'encoding': 'ISO-8859-1',\n",
      "                                     'language': ''},\n",
      "    'data/net_dbis/paper.txt': {   'confidence': 0.7299414179340399,\n",
      "                                   'encoding': 'ISO-8859-1',\n",
      "                                   'language': ''},\n",
      "    'data/net_dbis/paper_author.txt': {   'confidence': 1.0,\n",
      "                                          'encoding': 'ascii',\n",
      "                                          'language': ''},\n",
      "    'data/net_dbis/paper_conf.txt': {   'confidence': 1.0,\n",
      "                                        'encoding': 'ascii',\n",
      "                                        'language': ''}}\n"
     ]
    }
   ],
   "source": [
    "#detect encodings of files\n",
    "encodings = {}\n",
    "file_paths = [authors_csv_path, conferences_csv_path, papers_csv_path, paper_author_edges_csv_path, paper_conference_edges_csv_path]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        encodings[file_path] = (chardet.detect(f.read()))\n",
    "\n",
    "pp.pprint(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# store cvs contents in dataframe\n",
    "authors_df = pd.read_csv(authors_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[authors_csv_path][\"encoding\"])\n",
    "conferences_df = pd.read_csv(conferences_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[conferences_csv_path][\"encoding\"])\n",
    "papers_df = pd.read_csv(papers_csv_path, sep='       ', header=None, dtype={0:str, 1:str}, encoding=encodings[papers_csv_path][\"encoding\"])\n",
    "paper_author_edges_df = pd.read_csv(paper_author_edges_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[paper_author_edges_csv_path][\"encoding\"])\n",
    "paper_conference_df = pd.read_csv(paper_conference_edges_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[paper_conference_edges_csv_path][\"encoding\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
