{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import time\n",
    "import pickle\n",
    "import pprint\n",
    "import chardet\n",
    "from telegram import Bot\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize pretty printer\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initilize telegram bot\n",
    "token = \"350553078:AAEu70JDqMFcG_x5eBD3nqccTvc4aFNMKkg\"\n",
    "chat_id = \"126551968\"\n",
    "bot = Bot(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define dataset file paths\n",
    "dataset_path = 'data/net_dbis/'\n",
    "authors_csv_path = dataset_path + 'id_author.txt'\n",
    "conferences_csv_path = dataset_path + 'id_conf.txt'\n",
    "papers_csv_path = dataset_path + 'paper.txt'\n",
    "paper_author_edges_csv_path = dataset_path + 'paper_author.txt'\n",
    "paper_conference_edges_csv_path = dataset_path + 'paper_conf.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#detect encodings of files\n",
    "encodings = {}\n",
    "file_paths = [authors_csv_path, conferences_csv_path, papers_csv_path, paper_author_edges_csv_path, paper_conference_edges_csv_path]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        encodings[file_path] = (chardet.detect(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# store cvs contents in dataframe\n",
    "authors_df = pd.read_csv(authors_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[authors_csv_path][\"encoding\"])\n",
    "conferences_df = pd.read_csv(conferences_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[conferences_csv_path][\"encoding\"])\n",
    "papers_df = pd.read_csv(papers_csv_path, sep='     ', header=None, dtype={0:str, 1:str}, encoding=encodings[papers_csv_path][\"encoding\"])\n",
    "paper_author_edges_df = pd.read_csv(paper_author_edges_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[paper_author_edges_csv_path][\"encoding\"])\n",
    "paper_conference_edges_df = pd.read_csv(paper_conference_edges_csv_path, sep='\\t', header=None, dtype={0:str, 1:str}, encoding=encodings[paper_conference_edges_csv_path][\"encoding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give authors, papers and conferences unique node-ids\n",
    "authors_df[0] = 'a' + authors_df[0]\n",
    "conferences_df[0] = 'c' + conferences_df[0]\n",
    "papers_df[0] = 'p' + papers_df[0]\n",
    "paper_author_edges_df[0] = 'p' + paper_author_edges_df[0]\n",
    "paper_author_edges_df[1] = 'a' + paper_author_edges_df[1]\n",
    "paper_conference_edges_df[0] = 'p' + paper_conference_edges_df[0]\n",
    "paper_conference_edges_df[1] = 'c' + paper_conference_edges_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define networkx graph\n",
    "dbis_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define node and edge label constants\n",
    "AUTHOR = 'author'\n",
    "PAPER = 'paper'\n",
    "CONFERENCE = 'conference'\n",
    "PUBLISHED_AT = 'published_at'\n",
    "WRITTEN_BY = 'written_by' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60694 nodes in graph\n",
      "133596 nodes in graph\n",
      "134060 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add author, paper and conference nodes to graph\n",
    "dbis_graph.add_nodes_from(authors_df[0].tolist(), label=AUTHOR)\n",
    "print(\"{} nodes in graph\".format(dbis_graph.number_of_nodes()))\n",
    "dbis_graph.add_nodes_from(papers_df[0].tolist(), label=PAPER)\n",
    "print(\"{} nodes in graph\".format(dbis_graph.number_of_nodes()))\n",
    "dbis_graph.add_nodes_from(conferences_df[0].tolist(), label=CONFERENCE)\n",
    "print(\"{} nodes in graph\".format(dbis_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create edge tuples from dataframe\n",
    "paper_author_edges = list(zip(paper_author_edges_df[0].tolist(), paper_author_edges_df[1].tolist()))\n",
    "paper_conference_edges = list(zip(paper_conference_edges_df[0].tolist(), paper_conference_edges_df[1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72902 edges in graph\n",
      "134060 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add (paper)-[published_at]-(conference) edges to graph\n",
    "dbis_graph.add_edges_from(paper_conference_edges, label=PUBLISHED_AT)\n",
    "print(\"{} edges in graph\".format(dbis_graph.number_of_edges()))\n",
    "print(\"{} nodes in graph\".format(dbis_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265317 edges in graph\n",
      "134060 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add (paper)-[written_by]-(author) edges to graph\n",
    "dbis_graph.add_edges_from(paper_author_edges, label=WRITTEN_BY)\n",
    "print(\"{} edges in graph\".format(dbis_graph.number_of_edges()))\n",
    "print(\"{} nodes in graph\".format(dbis_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56163 authors with less than 8 papers are delete candidates\n"
     ]
    }
   ],
   "source": [
    "# extract top-5000 authors with regard to number of publications\n",
    "# add each author with less than 8 papers to the delete candidates\n",
    "num_of_top_k_authors = 5000\n",
    "author_degrees = []\n",
    "for node in list(dbis_graph.nodes):\n",
    "    if dbis_graph.nodes[node]['label'] == AUTHOR:\n",
    "        author_degrees.append(dbis_graph.degree(node))\n",
    "\n",
    "top_k_author_degree_threshold = min(nlargest(num_of_top_k_authors, author_degrees))\n",
    "delete_candidates = []\n",
    "\n",
    "for node in list(dbis_graph.nodes):\n",
    "    if dbis_graph.nodes[node]['label'] == AUTHOR:\n",
    "        if dbis_graph.degree(node) <= top_k_author_degree_threshold:\n",
    "            delete_candidates.append(node)\n",
    "\n",
    "print(\"{} authors with less than {} papers are delete candidates\".format(len(delete_candidates),top_k_author_degree_threshold+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167795 edges in graph\n",
      "77897 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# remove author delete candidates from graph\n",
    "dbis_graph.remove_nodes_from(delete_candidates)\n",
    "print(\"{} edges in graph\".format(dbis_graph.number_of_edges()))\n",
    "print(\"{} nodes in graph\".format(dbis_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read conference labels from file\n",
    "conference_labels_file_path = dataset_path + 'googlescholar_conference_labels.txt'\n",
    "conference_labels_df = pd.read_csv(conference_labels_file_path, sep=' ', header=None, dtype={0:str, 1:int})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
