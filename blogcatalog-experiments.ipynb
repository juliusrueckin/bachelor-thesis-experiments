{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import necessary stuff and python-wrapper of verse\n",
    "import os\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "from verse.python.wrapper import VERSE\n",
    "from multi_class_classification import MultiClassClassification\n",
    "from multi_label_classification import MultiLabelClassification\n",
    "from clustering import Clustering\n",
    "from link_prediction import LinkPrediction\n",
    "from experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize pretty printer\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure telegram notifier bot\n",
    "my_telegram_config = {\n",
    "    \"telegram\": {\n",
    "        \"token\": \"350553078:AAEu70JDqMFcG_x5eBD3nqccTvc4aFNMKkg\",\n",
    "        \"chat_id\": \"126551968\",\n",
    "        \"verbose\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define hyper-parameters\n",
    "n_hidden = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read *.bin file with precomputed embeddings\n",
    "embeddings_file_path = 'results/blogcatalog/blogcatalog_verse_embeddings.bin'\n",
    "embeddings_file = open(embeddings_file_path, \"r\")\n",
    "embeddings_file_content = np.fromfile(embeddings_file, dtype=np.float32)\n",
    "num_of_nodes = int(np.shape(embeddings_file_content)[0] / n_hidden)\n",
    "verse_ppr_embeddings = embeddings_file_content.reshape((num_of_nodes, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10351, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of trained embedding matrix\n",
    "np.shape(verse_ppr_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset file paths\n",
    "dataset_path = 'data/BlogCatalog-dataset/data/'\n",
    "friend_edges_csv_path = dataset_path + 'edges.csv'\n",
    "group_edges_csv_path = dataset_path + 'group-edges.csv'\n",
    "groups_csv_path = dataset_path + 'groups.csv'\n",
    "bloggers_csv_path = dataset_path + 'nodes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store cvs contents in dataframe\n",
    "friend_edges_df = pd.read_csv(friend_edges_csv_path, sep=',', header=None, dtype={0: str, 1:str})\n",
    "group_edges_df = pd.read_csv(group_edges_csv_path, sep=',', header=None, dtype={0: str, 1:str})\n",
    "groups_df = pd.read_csv(groups_csv_path, sep=',', header=None, dtype={0: str})\n",
    "bloggers_df = pd.read_csv(bloggers_csv_path, sep=',', header=None, dtype={0: str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# give bloggers and groups unique node-ids\n",
    "bloggers_df[0] = 'b' + bloggers_df[0]\n",
    "friend_edges_df = 'b' + friend_edges_df\n",
    "groups_df[0] = 'g' + groups_df[0]\n",
    "group_edges_df[0] = 'b' + group_edges_df[0]\n",
    "group_edges_df[1] = 'g' + group_edges_df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define networkx graph\n",
    "blog_catalog_graph = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define node and edge label constants\n",
    "IS_MEMBER_OF = 'is_member_of'\n",
    "IS_FRIEND_WITH = 'is_friend_with'\n",
    "BLOGGER = 'blogger'\n",
    "GROUP = 'group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10312 nodes in graph\n",
      "10351 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add blogger nodes to graph\n",
    "blog_catalog_graph.add_nodes_from(bloggers_df[0].tolist(), label=BLOGGER)\n",
    "print(\"{} nodes in graph\".format(blog_catalog_graph.number_of_nodes()))\n",
    "blog_catalog_graph.add_nodes_from(groups_df[0].tolist(), label=GROUP)\n",
    "print(\"{} nodes in graph\".format(blog_catalog_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create edge tuples from dataframe\n",
    "group_edges = list(zip(group_edges_df[0].tolist(), group_edges_df[1].tolist()))\n",
    "friend_edges = list(zip(friend_edges_df[0].tolist(), friend_edges_df[1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14476 edges in graph\n",
      "10351 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add (blogger)-[is_member_of]-(group) edges to graph\n",
    "blog_catalog_graph.add_edges_from(group_edges, label=IS_MEMBER_OF)\n",
    "print(\"{} edges in graph\".format(blog_catalog_graph.number_of_edges()))\n",
    "print(\"{} nodes in graph\".format(blog_catalog_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348459 edges in graph\n",
      "10351 nodes in graph\n"
     ]
    }
   ],
   "source": [
    "# add (blogger)-[is_friend_with]-(blogger) edges to graph\n",
    "blog_catalog_graph.add_edges_from(friend_edges, label=IS_FRIEND_WITH)\n",
    "print(\"{} edges in graph\".format(blog_catalog_graph.number_of_edges()))\n",
    "print(\"{} nodes in graph\".format(blog_catalog_graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg. node degree is 67.33\n"
     ]
    }
   ],
   "source": [
    "# compute average degree of all nodes in graph\n",
    "node_degrees = np.array(list(dict(blog_catalog_graph.degree(list(blog_catalog_graph.nodes))).values()),dtype=np.int64)\n",
    "avg_node_degree = np.mean(node_degrees)\n",
    "print(\"The avg. node degree is {}\".format(np.round(avg_node_degree, decimals=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load id-to-node mapping of verse embeddings\n",
    "id2node_filepath = 'data/BlogCatalog-dataset/data/blogcatalog_mapping_ids_to_nodes.p'\n",
    "id_2_node = {}\n",
    "with open(id2node_filepath, 'rb') as id_2_node_file:\n",
    "    id_2_node = pickle.load(id_2_node_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define tensorflow log-directory\n",
    "LOG_DIR = os.path.dirname(os.path.realpath('results/blogcatalog/visualizations/')) + '/visualizations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define node labels\n",
    "BLOGGER = 'blogger'\n",
    "GROUP = 'group'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write node labels to metadata tensorflow file\n",
    "node_labels = [blog_catalog_graph.nodes[id_2_node[i]]['label'] for i in range(np.shape(verse_ppr_embeddings)[0])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write node label list to file\n",
    "EXPORT_NODE_LABEL_META_DATA = True\n",
    "metadata_file_path = LOG_DIR + 'metadata_verse_node_labels.csv'\n",
    "\n",
    "if EXPORT_NODE_LABEL_META_DATA:\n",
    "    metadata_file = open(metadata_file_path, 'w')\n",
    "\n",
    "    for node_label in node_labels:\n",
    "        metadata_file.write(\"{}\\n\".format(node_label))\n",
    "\n",
    "    metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define tensorflow projector variables\n",
    "embedding_var = tf.Variable(verse_ppr_embeddings, name='blogcatalog_verse_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train tensorflow projector\n",
    "with tf.Session() as sess:\n",
    "    sess.run(embedding_var.initializer)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(LOG_DIR, sess.graph)\n",
    "    \n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding = config.embeddings.add()\n",
    "    embedding.tensor_name = embedding_var.name\n",
    "    embedding.metadata_path = metadata_file_path\n",
    "    \n",
    "    projector.visualize_embeddings(writer, config)\n",
    "    \n",
    "    saver_embed = tf.train.Saver([embedding_var])\n",
    "    saver_embed.save(sess, LOG_DIR + 'blogcatalog_verse_embeddings_viz.ckpt', 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
